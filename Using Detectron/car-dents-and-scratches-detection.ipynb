{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1572269,"sourceType":"datasetVersion","datasetId":929361}],"dockerImageVersionId":30043,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Use pip to install a Python package directly from a Git repository\n# The package is the COCO API from the GitHub repository\n# The #subdirectory=PythonAPI part specifies that only the PythonAPI subdirectory of the repository should be installed\n!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-01-15T07:11:50.923182Z","iopub.execute_input":"2024-01-15T07:11:50.923548Z","iopub.status.idle":"2024-01-15T07:12:05.680926Z","shell.execute_reply.started":"2024-01-15T07:11:50.923517Z","shell.execute_reply":"2024-01-15T07:12:05.679877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Enable inline plotting in Jupyter notebooks\n%matplotlib inline\n\n# Import necessary libraries and modules\nfrom pycocotools.coco import COCO  # COCO API for working with COCO datasets\nimport numpy as np\nimport skimage.io as io\nimport matplotlib.pyplot as plt\nimport pylab\nimport random\n\n# Set the default figure size for Matplotlib\npylab.rcParams['figure.figsize'] = (8.0, 10.0)\n\n# Import additional libraries for visualization\nimport os\nimport seaborn as sns  # Seaborn for statistical data visualization\nfrom matplotlib import colors\nfrom tensorboard.backend.event_processing import event_accumulator as ea\nfrom PIL import Image  # Python Imaging Library for image processing","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:12:26.475778Z","iopub.execute_input":"2024-01-15T07:12:26.476188Z","iopub.status.idle":"2024-01-15T07:12:26.488105Z","shell.execute_reply.started":"2024-01-15T07:12:26.476147Z","shell.execute_reply":"2024-01-15T07:12:26.487245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Set the directory paths and file names for COCO validation data\ndataDir = '../input/coco-car-damage-detection-dataset/val'  # Root directory for the COCO validation dataset\ndataType = 'COCO_val_annos'  # Type of annotations for the COCO validation dataset\nmul_dataType = 'COCO_mul_val_annos'  # Type of annotations for the COCO validation dataset with multiple annotations per image\n\n# Construct file paths for annotation files\nannFile = '{}/{}.json'.format(dataDir, dataType)  # File path for the COCO validation annotations\nmul_annFile = '{}/{}.json'.format(dataDir, mul_dataType)  # File path for the COCO validation annotations with multiple annotations\n\n# Set the directory path for images\nimg_dir = \"../input/coco-car-damage-detection-dataset/img\"  # Directory path for the COCO validation images","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:12:52.156290Z","iopub.execute_input":"2024-01-15T07:12:52.156629Z","iopub.status.idle":"2024-01-15T07:12:52.161927Z","shell.execute_reply.started":"2024-01-15T07:12:52.156600Z","shell.execute_reply":"2024-01-15T07:12:52.160993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Initialize COCO API for single-instance annotations\ncoco = COCO(annFile)\n\n# Initialize COCO API for multiple annotations per image\nmul_coco = COCO(mul_annFile)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:13:08.144463Z","iopub.execute_input":"2024-01-15T07:13:08.144825Z","iopub.status.idle":"2024-01-15T07:13:08.183885Z","shell.execute_reply.started":"2024-01-15T07:13:08.144789Z","shell.execute_reply":"2024-01-15T07:13:08.183004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Single Class - Damage Dataset\n# Load categories for single-instance annotations\ncats = coco.loadCats(coco.getCatIds())\n# Get category names\nnms = [cat['name'] for cat in cats]\n# Display COCO categories for damages\nprint('COCO categories for damages: \\n{}\\n'.format(', '.join(nms)))\n\n# Get unique supercategories for single-instance annotations\nnms = set([cat['supercategory'] for cat in cats])\n# Display COCO supercategories for damages\nprint('COCO supercategories for damages: \\n{}\\n'.format(', '.join(nms)))\n\n# Multi Class - Parts Dataset\n# Load categories for multiple annotations per image\nmul_cats = mul_coco.loadCats(mul_coco.getCatIds())\n# Get category names\nmul_nms = [mul_cat['name'] for mul_cat in mul_cats]\n# Display COCO categories for parts\nprint('COCO categories for parts: \\n{}\\n'.format(', '.join(mul_nms)))\n\n# Get unique supercategories for multiple annotations per image\nmul_nms = set([mul_cat['supercategory'] for mul_cat in mul_cats])\n# Display COCO supercategories for parts\nprint('COCO supercategories for parts: \\n{}\\n'.format(', '.join(mul_nms)))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:13:32.024481Z","iopub.execute_input":"2024-01-15T07:13:32.024836Z","iopub.status.idle":"2024-01-15T07:13:32.035092Z","shell.execute_reply.started":"2024-01-15T07:13:32.024801Z","shell.execute_reply":"2024-01-15T07:13:32.034096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get category IDs for the 'damage' category\ncatIds = coco.getCatIds(catNms=['damage'])\n# Get image IDs containing the 'damage' category\nimgIds = coco.getImgIds(catIds=catIds)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:13:46.538953Z","iopub.execute_input":"2024-01-15T07:13:46.539278Z","iopub.status.idle":"2024-01-15T07:13:46.543636Z","shell.execute_reply.started":"2024-01-15T07:13:46.539250Z","shell.execute_reply":"2024-01-15T07:13:46.542720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the random module to select a random image ID from the list of image IDs\nrandom_img_id = random.choice(imgIds)\n# Print a message indicating the randomly selected image ID\nprint(\"{} image id was selected at random from the {} list\".format(random_img_id, imgIds))","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:14:00.247153Z","iopub.execute_input":"2024-01-15T07:14:00.247479Z","iopub.status.idle":"2024-01-15T07:14:00.252718Z","shell.execute_reply.started":"2024-01-15T07:14:00.247452Z","shell.execute_reply":"2024-01-15T07:14:00.251957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the image ID using the randomly selected image ID\nimgId = coco.getImgIds(imgIds=[random_img_id])\n# Load the image details using the COCO API\nimg = coco.loadImgs(imgId)[0]\n# Print the details of the selected image\nprint(\"Image details \\n\", img)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:14:14.690569Z","iopub.execute_input":"2024-01-15T07:14:14.690946Z","iopub.status.idle":"2024-01-15T07:14:14.696467Z","shell.execute_reply.started":"2024-01-15T07:14:14.690912Z","shell.execute_reply":"2024-01-15T07:14:14.695493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Use skimage to read and load the image using the file path\nI = io.imread(img_dir + '/' + img['file_name'])\n\n# Plot the image using Matplotlib\nplt.axis('off')  # Turn off axis labels and ticks\nplt.imshow(I)  # Display the image\nplt.show()  # Show the plot","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:14:28.402435Z","iopub.execute_input":"2024-01-15T07:14:28.402788Z","iopub.status.idle":"2024-01-15T07:14:28.788709Z","shell.execute_reply.started":"2024-01-15T07:14:28.402751Z","shell.execute_reply":"2024-01-15T07:14:28.787685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Get annotation IDs for the damage annotations associated with the selected image\nannIds = coco.getAnnIds(imgIds=imgId, iscrowd=None)\n# Load the annotations using the COCO API\nanns = coco.loadAnns(annIds)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:14:53.368950Z","iopub.execute_input":"2024-01-15T07:14:53.369295Z","iopub.status.idle":"2024-01-15T07:14:53.373837Z","shell.execute_reply.started":"2024-01-15T07:14:53.369265Z","shell.execute_reply":"2024-01-15T07:14:53.373097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the original image\nplt.imshow(I)\n# Display axis labels and ticks\nplt.axis('on')\n# Use the COCO API's showAnns function to plot the damage annotations on the image\ncoco.showAnns(anns, draw_bbox=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:15:08.765345Z","iopub.execute_input":"2024-01-15T07:15:08.765672Z","iopub.status.idle":"2024-01-15T07:15:09.209679Z","shell.execute_reply.started":"2024-01-15T07:15:08.765644Z","shell.execute_reply":"2024-01-15T07:15:09.208978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Get annotation IDs for the parts annotations associated with the selected image\nmul_annIds = mul_coco.getAnnIds(imgIds=imgId, iscrowd=None)\n# Load the annotations using the COCO API\nmul_anns = mul_coco.loadAnns(mul_annIds)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:15:25.086438Z","iopub.execute_input":"2024-01-15T07:15:25.086764Z","iopub.status.idle":"2024-01-15T07:15:25.091253Z","shell.execute_reply.started":"2024-01-15T07:15:25.086736Z","shell.execute_reply":"2024-01-15T07:15:25.090339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary to map category_id to category name for parts annotations\ncategory_map = dict()\n\n# Iterate over the values (categories) in the cats dictionary of mul_coco\nfor ele in list(mul_coco.cats.values()):\n    # Update the dictionary with the mapping between category_id and category name\n    category_map.update({ele['id']: ele['name']})","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:15:40.319673Z","iopub.execute_input":"2024-01-15T07:15:40.320049Z","iopub.status.idle":"2024-01-15T07:15:40.324809Z","shell.execute_reply.started":"2024-01-15T07:15:40.320014Z","shell.execute_reply":"2024-01-15T07:15:40.323945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(category_map)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:15:59.399296Z","iopub.execute_input":"2024-01-15T07:15:59.399622Z","iopub.status.idle":"2024-01-15T07:15:59.403931Z","shell.execute_reply.started":"2024-01-15T07:15:59.399594Z","shell.execute_reply":"2024-01-15T07:15:59.403066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list to store the parts in the image\nparts = []\n\n# Iterate over the annotations in mul_anns\nfor region in mul_anns:\n    # Append the category name corresponding to the category_id to the parts list\n    parts.append(category_map[region['category_id']])\n\n# Print the list of parts\nprint(\"Parts are:\", parts)\n\n# Plot the original image\nI = io.imread(img_dir + '/' + img['file_name'])\nplt.imshow(I)\n# Display axis labels and ticks\nplt.axis('on')\n# Use mul_coco's showAnns function to plot the parts annotations on the image\nmul_coco.showAnns(mul_anns, draw_bbox=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:16:17.323850Z","iopub.execute_input":"2024-01-15T07:16:17.324229Z","iopub.status.idle":"2024-01-15T07:16:17.787981Z","shell.execute_reply.started":"2024-01-15T07:16:17.324198Z","shell.execute_reply":"2024-01-15T07:16:17.787149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{"trusted":true}},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Install Detectron2 using the specified wheel URL\n!python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/index.html","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-01-15T07:17:01.316270Z","iopub.execute_input":"2024-01-15T07:17:01.316607Z","iopub.status.idle":"2024-01-15T07:17:09.259638Z","shell.execute_reply.started":"2024-01-15T07:17:01.316576Z","shell.execute_reply":"2024-01-15T07:17:09.258540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"# Import PyTorch and torchvision libraries\nimport torch, torchvision\n\n# Print the version of PyTorch and whether CUDA (GPU support) is available\nprint(torch.__version__, torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:17:20.215628Z","iopub.execute_input":"2024-01-15T07:17:20.215981Z","iopub.status.idle":"2024-01-15T07:17:20.221530Z","shell.execute_reply.started":"2024-01-15T07:17:20.215948Z","shell.execute_reply":"2024-01-15T07:17:20.220543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use assert to check whether the PyTorch version starts with \"1.7\"\nassert torch.__version__.startswith(\"1.7\")","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:17:34.751226Z","iopub.execute_input":"2024-01-15T07:17:34.751571Z","iopub.status.idle":"2024-01-15T07:17:34.755619Z","shell.execute_reply.started":"2024-01-15T07:17:34.751540Z","shell.execute_reply":"2024-01-15T07:17:34.754696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the necessary modules from Detectron2\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# Import some common libraries\nimport numpy as np\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\nimport skimage.io as io\n\n# Import some common Detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# Set base params for plotting\nplt.rcParams[\"figure.figsize\"] = [16, 9]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:17:54.833358Z","iopub.execute_input":"2024-01-15T07:17:54.833718Z","iopub.status.idle":"2024-01-15T07:17:54.842621Z","shell.execute_reply.started":"2024-01-15T07:17:54.833686Z","shell.execute_reply":"2024-01-15T07:17:54.841835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the detectron2 utility script to collect environment information\n# Check for the presence of the \"failed\" word in the output\n# If \"failed\" is not present, then things are fine\n!python -m detectron2.utils.collect_env","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-01-15T07:18:11.154978Z","iopub.execute_input":"2024-01-15T07:18:11.155326Z","iopub.status.idle":"2024-01-15T07:18:16.433554Z","shell.execute_reply.started":"2024-01-15T07:18:11.155296Z","shell.execute_reply":"2024-01-15T07:18:16.432471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{"trusted":true}},{"cell_type":"code","source":"# Define the base directory for the COCO car damage detection dataset\ndataset_dir = \"../input/coco-car-damage-detection-dataset\"\n\n# Define the subdirectories for images, training data, and validation data\nimg_dir = \"img/\"\ntrain_dir = \"train/\"\nval_dir = \"val/\"\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:18:58.488552Z","iopub.execute_input":"2024-01-15T07:18:58.488884Z","iopub.status.idle":"2024-01-15T07:18:58.493696Z","shell.execute_reply.started":"2024-01-15T07:18:58.488855Z","shell.execute_reply":"2024-01-15T07:18:58.492508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you want to use a custom dataset while also reusing detectron2’s data loaders, you will need to\n\n*  Register your dataset (i.e., tell detectron2 how to obtain your dataset).\n\n* Optionally, register metadata for your dataset.","metadata":{}},{"cell_type":"code","source":"# Import the necessary function for registering COCO instances\nfrom detectron2.data.datasets import register_coco_instances\n\n# Register the training dataset\nregister_coco_instances(\n    \"car_dataset_train1\",  # Dataset name for training\n    {},  # Metadata dictionary (empty in this case)\n    os.path.join(dataset_dir, train_dir, \"COCO_train_annos.json\"),  # Path to the training annotations JSON file\n    os.path.join(dataset_dir, img_dir)  # Path to the directory containing training images\n)\n\n# Register the validation dataset\nregister_coco_instances(\n    \"car_dataset_val1\",  # Dataset name for validation\n    {},  # Metadata dictionary (empty in this case)\n    os.path.join(dataset_dir, val_dir, \"COCO_val_annos.json\"),  # Path to the validation annotations JSON file\n    os.path.join(dataset_dir, img_dir)  # Path to the directory containing validation images\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:20:50.130579Z","iopub.execute_input":"2024-01-15T07:20:50.130923Z","iopub.status.idle":"2024-01-15T07:20:50.137843Z","shell.execute_reply.started":"2024-01-15T07:20:50.130884Z","shell.execute_reply":"2024-01-15T07:20:50.136864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve dataset dictionaries for the registered training dataset\ndataset_dicts = DatasetCatalog.get(\"car_dataset_train\")\n\n# Retrieve metadata dictionaries for the registered training dataset\nmetadata_dicts = MetadataCatalog.get(\"car_dataset_train\")","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-01-15T07:21:09.248864Z","iopub.execute_input":"2024-01-15T07:21:09.249231Z","iopub.status.idle":"2024-01-15T07:21:09.262136Z","shell.execute_reply.started":"2024-01-15T07:21:09.249198Z","shell.execute_reply":"2024-01-15T07:21:09.261315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"...","metadata":{}},{"cell_type":"code","source":"# Implementing a custom Trainer Module to use COCO validation evaluation during training\n# TODO: Add custom data augmentation\n\nclass CocoTrainer(DefaultTrainer):\n    \"\"\"\n    Custom Trainer class that inherits from DefaultTrainer in Detectron2.\n    Overrides the build_evaluator method to use COCO validation evaluation during training.\n    \"\"\"\n\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        \"\"\"\n        Build a COCO evaluator for validation evaluation during training.\n\n        Args:\n            cfg (CfgNode): Detectron2 configuration node.\n            dataset_name (str): Name of the dataset.\n            output_folder (str): Output folder for evaluation results.\n\n        Returns:\n            COCOEvaluator: Evaluator for COCO validation evaluation.\n        \"\"\"\n\n        # If output_folder is not provided, create \"coco_eval\" folder\n        if output_folder is None:\n            os.makedirs(\"coco_eval\", exist_ok=True)\n            output_folder = \"coco_eval\"\n\n        # Return a COCOEvaluator for the specified dataset\n        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:22:13.229187Z","iopub.execute_input":"2024-01-15T07:22:13.229514Z","iopub.status.idle":"2024-01-15T07:22:13.236089Z","shell.execute_reply.started":"2024-01-15T07:22:13.229485Z","shell.execute_reply":"2024-01-15T07:22:13.235239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a Detectron2 configuration object\ncfg = get_cfg()\n\n# Merge with a Mask R-CNN configuration from the model zoo\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n\n# Set training and validation datasets\ncfg.DATASETS.TRAIN = (\"car_dataset_train\",)\ncfg.DATASETS.TEST = (\"car_dataset_val\",)\n\n# Configure data loader settings\ncfg.DATALOADER.NUM_WORKERS = 4\n\n# Use pre-trained weights from the model zoo\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n\n# Configure solver settings\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.001  # Pick a suitable learning rate\ncfg.SOLVER.WARMUP_ITERS = 700\ncfg.SOLVER.MAX_ITER = 800  # Adjust based on validation mAP performance\ncfg.SOLVER.STEPS = (600, 750)\ncfg.SOLVER.GAMMA = 0.1  # Adjust based on your preference\n\n# Configure ROI Heads settings\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # Faster, good enough for this dataset (default: 512)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Set to 1 for your one class (damage)\ncfg.MODEL.RETINANET.NUM_CLASSES = 1  # Set to 1 for your one class (damage)\n\n# Evaluation settings\ncfg.TEST.EVAL_PERIOD = 600\n\n# Clear any logs from previous runs\n# TODO: Add timestamp to logs\n!rm -rf {cfg.OUTPUT_DIR}\n\n# Create the output directory if it doesn't exist\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\n# Create and initialize the custom CocoTrainer\ntrainer = CocoTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-01-15T07:22:46.719250Z","iopub.execute_input":"2024-01-15T07:22:46.719650Z","iopub.status.idle":"2024-01-15T07:28:41.868195Z","shell.execute_reply.started":"2024-01-15T07:22:46.719617Z","shell.execute_reply":"2024-01-15T07:28:41.867252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"markdown","source":"..","metadata":{}},{"cell_type":"code","source":"def smooth(scalars, weight=0.6):\n    \"\"\"\n    Smoothes a list of scalars using exponential moving average.\n\n    Reference: https://github.com/plotly/dash-live-model-training/blob/master/app.py#L163\n    \"\"\"\n    last = scalars[0]\n    smoothed = list()\n    for point in scalars:\n        smoothed_val = last * weight + (1 - weight) * point\n        smoothed.append(smoothed_val)\n        last = smoothed_val\n    return smoothed\n\n\ndef plot(logdir: str, savedir: str, smoothing: float = 0.6, no_title=False, no_legend=False, no_axis_labels=False):\n    \"\"\"Re-draw the tf summary events plots using seaborn.\n\n    :param logdir: Path to the directory having event logs.\n    :param savedir: Path to save the seaborn graphs.\n    :param smoothing: Smoothing window space for the plots.\n    :param no_title: If True, do not display titles on the plots.\n    :param no_legend: If True, do not display legends on the plots.\n    :param no_axis_labels: If True, do not display axis labels on the plots.\n    :return: List of paths to the saved plots.\n    \"\"\"\n    assert 0 <= smoothing <= 1, 'Smoothing value should be in [0,1]'\n    \n    plots = []\n    \n    sns.set(style=\"darkgrid\")\n    sns.set_context(\"paper\")\n\n    # Collect data\n    # We recognize all files which have tfevents\n    scalars_info = {}\n    for root, dirs, files in os.walk(logdir):\n        for event_file in [x for x in files if 'tfevents' in x]:\n            event_path = os.path.join(root, event_file)\n\n            acc = ea.EventAccumulator(event_path)\n            acc.Reload()\n\n            # Only support scalar now\n            scalar_list = acc.Tags()['scalars']\n            for tag in scalar_list:\n                x = [s.step for s in acc.Scalars(tag)]\n                y = [s.value for s in acc.Scalars(tag)]\n                data = {'x': x, 'y': y, 'legend': root.split(logdir)[1][1:] if root != logdir else None}\n                if tag not in scalars_info:\n                    scalars_info[tag] = [data]\n                else:\n                    scalars_info[tag].append(data)\n\n    # We recognize groups assuming each group name has /\n    # And, each group is saved in a separate directory\n    for tag, tag_data in scalars_info.items():\n        _split = tag.split('/')\n        if len(_split) <= 1:\n            _path = os.path.join(savedir, 'seaborn')\n            _name = _split[0]\n        else:\n            _path = os.path.join(savedir, 'seaborn', _split[0])\n            _name = ''.join(_split[1:])\n\n        os.makedirs(_path, exist_ok=True)\n\n        color_list = list(sns.color_palette(palette='dark', n_colors=len(tag_data)))[::-1]\n        for data in tag_data:\n            x, y = data['x'], data['y']\n            y_smooth = smooth(y, weight=smoothing)\n            current_color = color_list.pop()\n            _plt = sns.lineplot(x, y, color=colors.to_rgba(current_color, alpha=0.4))\n            _legend = data['legend'] if not no_legend else None\n            _plt = sns.lineplot(x, y_smooth, label=data['legend'], color=current_color)\n\n        if not no_axis_labels:\n            _plt.set(xlabel='x', ylabel='y')\n        if not no_title:\n            _plt.set_title(_name.capitalize())\n        \n        plots.append(os.path.join(_path, _name + '.png'))\n        plt.savefig(os.path.join(_path, _name + '.png'))\n        plt.clf()\n    return plots","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:28:41.871534Z","iopub.execute_input":"2024-01-15T07:28:41.871848Z","iopub.status.idle":"2024-01-15T07:28:41.897837Z","shell.execute_reply.started":"2024-01-15T07:28:41.871815Z","shell.execute_reply":"2024-01-15T07:28:41.896647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plots = plot(logdir= './output', savedir= './')","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:28:41.899053Z","iopub.execute_input":"2024-01-15T07:28:41.899364Z","iopub.status.idle":"2024-01-15T07:28:49.480300Z","shell.execute_reply.started":"2024-01-15T07:28:41.899336Z","shell.execute_reply":"2024-01-15T07:28:49.479485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plots","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:28:49.481609Z","iopub.execute_input":"2024-01-15T07:28:49.481889Z","iopub.status.idle":"2024-01-15T07:28:49.487745Z","shell.execute_reply.started":"2024-01-15T07:28:49.481864Z","shell.execute_reply":"2024-01-15T07:28:49.486967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_dpi = 1000\nfig, ax = plt.subplots(4, 1, figsize=(10, 8), dpi=my_dpi)\n\nax[0].set_title('Total Loss', fontsize=7)\nax[0].set_xticks([])\nax[0].set_yticks([])\nax[0].imshow(Image.open('./seaborn/total_loss.png'))\n\nax[1].set_title('Bounding Box Average Precision', fontsize=7)\nax[1].set_xticks([])\nax[1].set_yticks([])\nax[1].imshow(Image.open('./seaborn/bbox/AP.png'))\n\nax[2].set_title('Segmentation Average Precision', fontsize=7)\nax[2].set_xticks([])\nax[2].set_yticks([])\nax[2].imshow(Image.open('./seaborn/segm/AP.png'))\n\nax[3].set_title('Class accuracy', fontsize=7)\nax[3].set_xticks([])\nax[3].set_yticks([])\nax[3].imshow(Image.open('./seaborn/fast_rcnn/cls_accuracy.png'))","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:28:49.490519Z","iopub.execute_input":"2024-01-15T07:28:49.490857Z","iopub.status.idle":"2024-01-15T07:28:53.000061Z","shell.execute_reply.started":"2024-01-15T07:28:49.490827Z","shell.execute_reply":"2024-01-15T07:28:52.999173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* I think the training worked well as the loss has decreased over the runs.\n* The class accuracy and average precision has improved over the runs.","metadata":{}},{"cell_type":"markdown","source":"...","metadata":{}},{"cell_type":"code","source":"# Create a COCOEvaluator for the \"car_dataset_val\" dataset using the provided configuration\nevaluator = COCOEvaluator(\"car_dataset_val\", cfg, False, output_dir=\"./output/\")\n\n# Build a test loader for the validation dataset\nval_loader = build_detection_test_loader(cfg, \"car_dataset_val\")\n\n# Perform inference on the validation dataset using the trainer's model and the created evaluator\nevaluation_results = inference_on_dataset(trainer.model, val_loader, evaluator)\n\n# Print the evaluation results to the console\nprint(evaluation_results)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-01-15T07:28:53.001617Z","iopub.execute_input":"2024-01-15T07:28:53.001922Z","iopub.status.idle":"2024-01-15T07:28:57.482085Z","shell.execute_reply.started":"2024-01-15T07:28:53.001875Z","shell.execute_reply":"2024-01-15T07:28:57.481222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Set the model weights for inference\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n\n# Set a custom testing threshold for the model's ROI heads\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n\n# Specify the dataset for testing (validation dataset in this case)\ncfg.DATASETS.TEST = (\"car_dataset_val\", )\n\n# Create a DefaultPredictor using the configured settings\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:28:57.484210Z","iopub.execute_input":"2024-01-15T07:28:57.484602Z","iopub.status.idle":"2024-01-15T07:28:58.409872Z","shell.execute_reply.started":"2024-01-15T07:28:57.484558Z","shell.execute_reply":"2024-01-15T07:28:58.409153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve validation dataset and metadata\nval_dataset_dicts = DatasetCatalog.get(\"car_dataset_val\")\nval_metadata_dicts = MetadataCatalog.get(\"car_dataset_val\")","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:28:58.411246Z","iopub.execute_input":"2024-01-15T07:28:58.411621Z","iopub.status.idle":"2024-01-15T07:28:58.418400Z","shell.execute_reply.started":"2024-01-15T07:28:58.411582Z","shell.execute_reply":"2024-01-15T07:28:58.417549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a 2x2 subplot for visualization\nfig, ax = plt.subplots(2, 2, figsize=(16, 12))\nindices = [ax[0][0], ax[1][0], ax[0][1], ax[1][1]]\n\n# Iterate over a random sample of 4 validation dataset entries\ni = -1\nfor d in random.sample(val_dataset_dicts, 4):\n    i += 1\n    im = io.imread(d[\"file_name\"])  # Load image\n    outputs = predictor(im)  # Perform inference using the predictor\n\n    # Visualize the results using Detectron2's Visualizer\n    v = Visualizer(im[:, :, ::-1], metadata=val_metadata_dicts, scale=0.5, instance_mode=ColorMode.IMAGE_BW)\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n    # Display the visualization in the subplot\n    indices[i].grid(False)\n    indices[i].imshow(out.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:28:58.419637Z","iopub.execute_input":"2024-01-15T07:28:58.419944Z","iopub.status.idle":"2024-01-15T07:29:00.591556Z","shell.execute_reply.started":"2024-01-15T07:28:58.419890Z","shell.execute_reply":"2024-01-15T07:29:00.590645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion\n* I think the results are quite fine even when the training data was around 60 images.\n* Data augmentation can significantly improve the results.\n* I will try doing multiclass object detection next.","metadata":{"trusted":true}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/.git","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:54:36.756202Z","iopub.execute_input":"2024-01-15T07:54:36.756569Z","iopub.status.idle":"2024-01-15T07:54:37.780633Z","shell.execute_reply.started":"2024-01-15T07:54:36.756538Z","shell.execute_reply":"2024-01-15T07:54:37.779552Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"!git init","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:54:48.608327Z","iopub.execute_input":"2024-01-15T07:54:48.608670Z","iopub.status.idle":"2024-01-15T07:54:49.609715Z","shell.execute_reply.started":"2024-01-15T07:54:48.608638Z","shell.execute_reply":"2024-01-15T07:54:49.608842Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"Initialized empty Git repository in /kaggle/working/.git/\n","output_type":"stream"}]},{"cell_type":"code","source":"!git config --global user.email \"vamshipallapuece@gmail.com\"\n!git config --global user.name \"Vamshipallapu\"","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:54:57.413035Z","iopub.execute_input":"2024-01-15T07:54:57.413396Z","iopub.status.idle":"2024-01-15T07:54:59.411106Z","shell.execute_reply.started":"2024-01-15T07:54:57.413364Z","shell.execute_reply":"2024-01-15T07:54:59.409663Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# Replace the repository URL with your actual repository URL\n!git remote add origin https://github.com/Vamshipallapu/Round_4_Binary_S_company_vamshi.git","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:55:17.983681Z","iopub.execute_input":"2024-01-15T07:55:17.984103Z","iopub.status.idle":"2024-01-15T07:55:18.980968Z","shell.execute_reply.started":"2024-01-15T07:55:17.984064Z","shell.execute_reply":"2024-01-15T07:55:18.979816Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"!git add .\n!git commit -m \"commit first\"","metadata":{"execution":{"iopub.status.busy":"2024-01-15T07:55:35.096539Z","iopub.execute_input":"2024-01-15T07:55:35.096913Z","iopub.status.idle":"2024-01-15T07:55:46.268472Z","shell.execute_reply.started":"2024-01-15T07:55:35.096866Z","shell.execute_reply":"2024-01-15T07:55:46.267425Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"[master (root-commit) 951f81c] commit first\n 40 files changed, 44 insertions(+)\n create mode 100644 coco_eval/coco_instances_results.json\n create mode 100644 coco_eval/instances_predictions.pth\n create mode 100644 output/coco_instances_results.json\n create mode 100644 output/events.out.tfevents.1705303368.4ccf39fe7c6c.17.2\n create mode 100644 output/instances_predictions.pth\n create mode 100644 output/last_checkpoint\n create mode 100644 output/metrics.json\n create mode 100644 output/model_final.pth\n create mode 100644 seaborn/bbox/AP.png\n create mode 100644 seaborn/bbox/AP50.png\n create mode 100644 seaborn/bbox/AP75.png\n create mode 100644 seaborn/bbox/APl.png\n create mode 100644 seaborn/bbox/APm.png\n create mode 100644 seaborn/bbox/APs.png\n create mode 100644 seaborn/data_time.png\n create mode 100644 seaborn/eta_seconds.png\n create mode 100644 seaborn/fast_rcnn/cls_accuracy.png\n create mode 100644 seaborn/fast_rcnn/false_negative.png\n create mode 100644 seaborn/fast_rcnn/fg_cls_accuracy.png\n create mode 100644 seaborn/loss_box_reg.png\n create mode 100644 seaborn/loss_cls.png\n create mode 100644 seaborn/loss_mask.png\n create mode 100644 seaborn/loss_rpn_cls.png\n create mode 100644 seaborn/loss_rpn_loc.png\n create mode 100644 seaborn/lr.png\n create mode 100644 seaborn/mask_rcnn/accuracy.png\n create mode 100644 seaborn/mask_rcnn/false_negative.png\n create mode 100644 seaborn/mask_rcnn/false_positive.png\n create mode 100644 seaborn/roi_head/num_bg_samples.png\n create mode 100644 seaborn/roi_head/num_fg_samples.png\n create mode 100644 seaborn/rpn/num_neg_anchors.png\n create mode 100644 seaborn/rpn/num_pos_anchors.png\n create mode 100644 seaborn/segm/AP.png\n create mode 100644 seaborn/segm/AP50.png\n create mode 100644 seaborn/segm/AP75.png\n create mode 100644 seaborn/segm/APl.png\n create mode 100644 seaborn/segm/APm.png\n create mode 100644 seaborn/segm/APs.png\n create mode 100644 seaborn/time.png\n create mode 100644 seaborn/total_loss.png\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Replace 'your_folder' with the name of the folder you want to download\nfolder_to_download = 'your_folder'\n\n# Check if the folder exists\nif os.path.exists(folder_to_download):\n    # Create a zip file containing the folder\n    shutil.make_archive(folder_to_download, 'zip', folder_to_download)\n\n    # Provide a clickable link to download the zip file\n    from IPython.display import FileLink\n    zip_file_path = f'{folder_to_download}.zip'\n    FileLink(zip_file_path)\nelse:\n    print(f\"The folder '{folder_to_download}' does not exist.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-15T08:07:51.128833Z","iopub.execute_input":"2024-01-15T08:07:51.129194Z","iopub.status.idle":"2024-01-15T08:07:51.136585Z","shell.execute_reply.started":"2024-01-15T08:07:51.129166Z","shell.execute_reply":"2024-01-15T08:07:51.135578Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"The folder 'your_folder' does not exist.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}